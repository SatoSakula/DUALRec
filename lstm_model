import tensorflow as tf
from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate, GlobalAveragePooling1D
from tensorflow.keras.models import Model

# Updated parameters based on actual data shapes
seq_length = 30
max_title_length = 10
n_genres = 18
vocab_size = 1000
title_vocab_size = 5000


def create_fixed_enhanced_model(seq_length=30, return_lstm_output=False):
    movie_input = Input(shape=(seq_length,), name='movie_sequence')
    title_input = Input(shape=(seq_length, max_title_length), name='title_sequence')
    genre_input = Input(shape=(seq_length, n_genres), name='genre_features')

    # Embeddings and processing (same as before)
    movie_embedded = Embedding(vocab_size, 128, name="movie_embedding")(movie_input)

    title_embedded_list = []
    for i in range(seq_length):
        title_slice = tf.keras.layers.Lambda(lambda x: x[:, i, :])(title_input)
        title_emb = Embedding(title_vocab_size, 64)(title_slice)
        title_pooled = GlobalAveragePooling1D()(title_emb)
        title_embedded_list.append(title_pooled)

    title_embedded = tf.keras.layers.Lambda(lambda x: tf.stack(x, axis=1))(title_embedded_list)
    genre_dense = Dense(64, activation='relu')(genre_input)

    combined_features = Concatenate()([movie_embedded, title_embedded, genre_dense])

    # LSTM layers
    x = LSTM(256, return_sequences=True, dropout=0.3)(combined_features)
    lstm_output = LSTM(128, dropout=0.3)(x)

    if return_lstm_output:
        return Model(inputs=[movie_input, title_input, genre_input], outputs=lstm_output)

    # Otherwise, continue to final output
    x = Dense(256, activation='relu')(lstm_output)
    x = Dropout(0.3)(x)
    output = Dense(vocab_size, activation='softmax')(x)

    return Model(inputs=[movie_input, title_input, genre_input], outputs=output)



# Data type fix for titles
def fix_title_dtype(train_titles, val_titles):
    """Convert title data to int32 as expected by Embedding layer"""
    train_titles_fixed = train_titles.astype(np.int32)
    val_titles_fixed = val_titles.astype(np.int32)
    return train_titles_fixed, val_titles_fixed

# Fix data types
train_titles_fixed, val_titles_fixed = fix_title_dtype(train_titles, val_titles)

# Create model
model = create_fixed_enhanced_model(seq_length=30)

# Compile
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy', tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]
)

# Train with fixed data
history = model.fit(
    [train_movie_ids, train_titles_fixed, train_genres],
    train_y,
    batch_size=128,
    epochs=10,
    validation_data=([val_movie_ids, val_titles_fixed, val_genres], val_y)
)

plot_training_history(history)
plot_improvement_over_time(history)
create_summary_table(history)

def save_lstm_weights(model, save_path):
    """
    Extract and save LSTM layer weights from the model

    Args:
        model: The trained Keras model
        save_path: Directory to save the weights
    """
    import os

    # Create directory if it doesn't exist
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    # Find LSTM layers in the model
    lstm_layers = []
    for layer in model.layers:
        if 'lstm' in layer.name.lower():
            lstm_layers.append(layer)

    print(f"Found {len(lstm_layers)} LSTM layers in the model")

    # Save weights for each LSTM layer
    for i, lstm_layer in enumerate(lstm_layers):
        # Get weights
        weights = lstm_layer.get_weights()

        # Save weights
        weights_path = os.path.join(save_path, f"lstm_{i+1}_weights.npz")
        np.savez(weights_path, *weights)

        # Print layer info
        print(f"Saved weights for {lstm_layer.name} to {weights_path}")
        print(f"  - Shape of weights: {[w.shape for w in weights]}")

    # Save model diagram
    try:
        from tensorflow.keras.utils import plot_model
        plot_model(model, to_file=os.path.join(save_path, 'model_diagram.png'), show_shapes=True)
        print(f"Saved model diagram to {os.path.join(save_path, 'model_diagram.png')}")
    except Exception as e:
        print(f"Could not save model diagram: {e}")

    # Also save complete model for reference
    model.save(os.path.join(save_path, 'full_model.h5'))
    print(f"Saved complete model to {os.path.join(save_path, 'full_model.h5')}")

    return lstm_layers

# Save LSTM weights
print("\nSaving LSTM weights...")
save_path = '/content/drive/MyDrive/Colab Notebooks/lstm_weights'
# Save the LSTM model weights
lstm_layers = save_lstm_weights(model=create_fixed_enhanced_model(seq_length=30), save_path=save_path)
